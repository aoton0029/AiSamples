{
  "meta": {
    "instanceId": "558d88703fb65b2d0e44613bc35916258b0f0bf983c5d4730c00c424b77ca36a",
    "templateCredsSetupCompleted": true
  },
  "nodes": [
    {
      "id": "cb29d79a-40dc-4077-8810-45c695229609",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        0,
        0
      ],
      "webhookId": "349f7ccf-6700-42b1-8137-fdde62c4bdfa",
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.1
    },
    {
      "id": "c090dbad-f2dc-4db5-84c0-0f96ab5fb922",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        220,
        0
      ],
      "parameters": {
        "options": {
          "systemMessage": "You are a helpful assistant. You have access to two MCP Servers. One which has access to a RAG Database, and one which has access to a tool to search google.\n\nWhen you get a question about current events, you use the search engine MCP Server to fetch information.\n\nWhen people ask more general questions, you use your RAG Database"
        }
      },
      "typeVersion": 2
    },
    {
      "id": "8688fdd5-7cb6-4d45-bda5-39c31f24ffcd",
      "name": "Ollama Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "position": [
        -120,
        240
      ],
      "parameters": {
        "options": {}
      },
      "credentials": {
        "ollamaApi": {
          "id": "xHuYe0MDGOs9IpBW",
          "name": "Local Ollama service"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "2db79ee1-07c3-49bc-863a-129066a4c758",
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        60,
        300
      ],
      "parameters": {},
      "typeVersion": 1.3
    },
    {
      "id": "c82053cf-99f2-40cb-8c07-eac3f199f7b2",
      "name": "MCP Client: RAG",
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "position": [
        360,
        300
      ],
      "parameters": {
        "sseEndpoint": "http://localhost:5678/mcp/8d7910ab-f0db-4042-9da9-f580647a8a8e"
      },
      "typeVersion": 1
    },
    {
      "id": "020a7821-5c15-48cb-a5bd-1d3251130b80",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        280,
        220
      ],
      "parameters": {
        "color": 3,
        "height": 240,
        "content": "## MCP Client: RAG\n"
      },
      "typeVersion": 1
    },
    {
      "id": "3d0b7c23-18f4-49ec-bb2a-4192959250e8",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        600,
        220
      ],
      "parameters": {
        "color": 6,
        "width": 400,
        "height": 240,
        "content": "## MCP Client: Bright Data\n"
      },
      "typeVersion": 1
    },
    {
      "id": "c41ee2cf-73ef-4f38-bc0b-36ff5091d18c",
      "name": "MCP Client:BD_Tools",
      "type": "n8n-nodes-mcp.mcpClientTool",
      "position": [
        680,
        300
      ],
      "parameters": {},
      "credentials": {
        "mcpClientApi": {
          "id": "gtICJ1VBUVNpQahr",
          "name": "MCP Client (STDIO) account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "85a32e4d-02c0-4811-a33d-3d77f4705f35",
      "name": "MCP Client:BD_Execute",
      "type": "n8n-nodes-mcp.mcpClientTool",
      "position": [
        840,
        300
      ],
      "parameters": {
        "toolName": "search_engine",
        "operation": "executeTool",
        "toolParameters": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Tool_Parameters', ``, 'json') }}"
      },
      "credentials": {
        "mcpClientApi": {
          "id": "gtICJ1VBUVNpQahr",
          "name": "MCP Client (STDIO) account"
        }
      },
      "typeVersion": 1
    }
  ],
  "pinData": {},
  "connections": {
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "MCP Client: RAG": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "MCP Client:BD_Tools": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP Client:BD_Execute": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}