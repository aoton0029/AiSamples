# Ollama Model Template Configuration
# Author: aoton0029
# Date: 2025-08-19

model:
  name: "${MODEL_NAME}"
  file: "${MODEL_FILE}"
  config: "${MODEL_CONFIG}"

server:
  host: "0.0.0.0"
  port: 11434
  timeout: 300
  
parameters:
  temperature: 0.7
  top_p: 0.9
  top_k: 40
  repeat_penalty: 1.1
  stop_sequences: ["</s>", "<|im_end|>"]

system:
  message: "You are a helpful AI assistant."
  context_length: 2048
  
performance:
  batch_size: 1
  threads: -1
  gpu_layers: -1

logging:
  level: "info"
  format: "json"
  
health:
  enabled: true
  interval: 30
  timeout: 10
  retries: 3