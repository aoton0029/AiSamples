# Ollama Base Configuration
# Author: aoton0029
# Date: 2025-08-19

[server]
host = 0.0.0.0
port = 11434
timeout = 300
max_concurrent_requests = 1

[logging]
level = info
file = /var/log/ollama.log
max_size = 100MB
max_files = 3

[models]
directory = /root/.ollama/models
cache_size = 2GB
auto_load = true

[security]
cors_origins = *
api_auth = false

[performance]
gpu_acceleration = auto
memory_limit = 8GB
cpu_threads = auto

[features]
metrics_enabled = true
health_check = true
model_preload = false